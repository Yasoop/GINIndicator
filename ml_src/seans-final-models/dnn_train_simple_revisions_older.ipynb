{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *NOTE: this notebook has been replaced by a newer optimizer*\n",
    "# Training of Final DNN\n",
    "This jupyter notebook file is where the final version of the DNN is trained and saved. It is written to be fully reproducible.\n",
    "\n",
    "I created a new env to run this file and its sister file (dnn_load_test.ipynb). It's probably easiest to create a new conda env using this command:\n",
    "\n",
    "and this YAML file content:\n",
    "\n",
    "``` yaml\n",
    "name: consensus-tf\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11.5\n",
    "  - matplotlib=3.10\n",
    "  - scikit-learn=1.6.1\n",
    "  - tensorflow=2.12.0\n",
    "  - notebook=7.3.2\n",
    "  - pandas=2.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 02:37:58.500316: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 4ms/step - loss: 60.2719 - mae: 6.7994 - val_loss: 62.6242 - val_mae: 6.7548\n",
      "Epoch 2/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 33.4530 - mae: 4.7031 - val_loss: 47.6119 - val_mae: 5.6585\n",
      "Epoch 3/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 19.9427 - mae: 3.2350 - val_loss: 31.1289 - val_mae: 4.0675\n",
      "Epoch 4/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 12.8909 - mae: 2.5316 - val_loss: 19.3633 - val_mae: 2.8178\n",
      "Epoch 5/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 8.9301 - mae: 2.1151 - val_loss: 13.6047 - val_mae: 2.3172\n",
      "Epoch 6/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 9.1263 - mae: 2.2387 - val_loss: 10.9669 - val_mae: 2.0536\n",
      "Epoch 7/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 7.3196 - mae: 2.0021 - val_loss: 8.9044 - val_mae: 1.8771\n",
      "Epoch 8/300\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.7927 - mae: 2.0504 - val_loss: 6.2478 - val_mae: 1.6963\n",
      "Epoch 9/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 7.3028 - mae: 1.9740 - val_loss: 4.8766 - val_mae: 1.5726\n",
      "Epoch 10/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 6.4126 - mae: 1.8357 - val_loss: 4.7232 - val_mae: 1.5629\n",
      "Epoch 11/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 6.2252 - mae: 1.8723 - val_loss: 4.9497 - val_mae: 1.5183\n",
      "Epoch 12/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.4848 - mae: 1.7741 - val_loss: 4.0570 - val_mae: 1.4927\n",
      "Epoch 13/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.9348 - mae: 1.6328 - val_loss: 4.7145 - val_mae: 1.5616\n",
      "Epoch 14/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.5020 - mae: 1.7512 - val_loss: 5.0491 - val_mae: 1.6175\n",
      "Epoch 15/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.7810 - mae: 1.6147 - val_loss: 5.2071 - val_mae: 1.6059\n",
      "Epoch 16/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.1293 - mae: 1.5246 - val_loss: 4.8817 - val_mae: 1.5757\n",
      "Epoch 17/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.1508 - mae: 1.6763 - val_loss: 3.7112 - val_mae: 1.3319\n",
      "Epoch 18/300\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 5.0703 - mae: 1.7166 - val_loss: 2.5535 - val_mae: 1.1541\n",
      "Epoch 19/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.2393 - mae: 1.7050 - val_loss: 2.9485 - val_mae: 1.2050\n",
      "Epoch 20/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.2164 - mae: 1.5433 - val_loss: 2.7161 - val_mae: 1.1583\n",
      "Epoch 21/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.2131 - mae: 1.6419 - val_loss: 3.4070 - val_mae: 1.3974\n",
      "Epoch 22/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.9232 - mae: 1.6249 - val_loss: 3.2231 - val_mae: 1.2804\n",
      "Epoch 23/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.6977 - mae: 1.6252 - val_loss: 3.0948 - val_mae: 1.2843\n",
      "Epoch 24/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.2677 - mae: 1.5596 - val_loss: 3.1420 - val_mae: 1.3001\n",
      "Epoch 25/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.2804 - mae: 1.6400 - val_loss: 3.2249 - val_mae: 1.2668\n",
      "Epoch 26/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.3647 - mae: 1.5928 - val_loss: 3.4209 - val_mae: 1.3705\n",
      "Epoch 27/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.7354 - mae: 1.4758 - val_loss: 3.3857 - val_mae: 1.3750\n",
      "Epoch 28/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.6357 - mae: 1.5413 - val_loss: 3.4017 - val_mae: 1.2895\n",
      "Epoch 29/300\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.7135 - mae: 1.4423 - val_loss: 3.6443 - val_mae: 1.3589\n",
      "Epoch 30/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.2579 - mae: 1.5518 - val_loss: 2.9475 - val_mae: 1.2980\n",
      "Epoch 31/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.7131 - mae: 1.4622 - val_loss: 2.4376 - val_mae: 1.1819\n",
      "Epoch 32/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.1095 - mae: 1.4939 - val_loss: 3.7195 - val_mae: 1.3501\n",
      "Epoch 33/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.4576 - mae: 1.4177 - val_loss: 2.7390 - val_mae: 1.2855\n",
      "Epoch 34/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.4607 - mae: 1.3872 - val_loss: 2.9091 - val_mae: 1.3808\n",
      "Epoch 35/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.2081 - mae: 1.3497 - val_loss: 3.0580 - val_mae: 1.3965\n",
      "Epoch 36/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.0777 - mae: 1.5429 - val_loss: 2.2099 - val_mae: 1.1623\n",
      "Epoch 37/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.1905 - mae: 1.5183 - val_loss: 3.0256 - val_mae: 1.2890\n",
      "Epoch 38/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.6538 - mae: 1.4517 - val_loss: 2.7748 - val_mae: 1.3273\n",
      "Epoch 39/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 4.2714 - mae: 1.5550 - val_loss: 2.5544 - val_mae: 1.2049\n",
      "Epoch 40/300\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.4058 - mae: 1.4082 - val_loss: 3.0252 - val_mae: 1.2576\n",
      "Epoch 41/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.3690 - mae: 1.3801 - val_loss: 2.5772 - val_mae: 1.1784\n",
      "Epoch 42/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.1754 - mae: 1.3498 - val_loss: 2.7385 - val_mae: 1.2215\n",
      "Epoch 43/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.0712 - mae: 1.3571 - val_loss: 2.9483 - val_mae: 1.2737\n",
      "Epoch 44/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.9715 - mae: 1.2578 - val_loss: 3.0414 - val_mae: 1.2411\n",
      "Epoch 45/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.3025 - mae: 1.3809 - val_loss: 2.6829 - val_mae: 1.2118\n",
      "Epoch 46/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.0178 - mae: 1.3757 - val_loss: 2.9134 - val_mae: 1.1942\n",
      "Epoch 47/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.6696 - mae: 1.4589 - val_loss: 2.5640 - val_mae: 1.1799\n",
      "Epoch 48/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.7848 - mae: 1.4258 - val_loss: 2.7452 - val_mae: 1.1199\n",
      "Epoch 49/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.9083 - mae: 1.2524 - val_loss: 2.9494 - val_mae: 1.2310\n",
      "Epoch 50/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.2329 - mae: 1.3478 - val_loss: 3.9713 - val_mae: 1.2992\n",
      "Epoch 51/300\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 3.4924 - mae: 1.3455 - val_loss: 3.7445 - val_mae: 1.3756\n",
      "13/13 [==============================] - 0s 550us/step\n",
      "MAE: 1.13\n",
      "MSE: 2.61\n",
      "RMSE: 1.62\n",
      "RÂ² Score: 0.83\n",
      "\n",
      "Predicted Unemployment: 6.41%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 11 # for reproduciblity\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../../datasets/MEGAFRAME_CLEANEDV2.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=['UNEMP', 'Reference area', 'REF_AREA', 'TIME_PERIOD'])\n",
    "y = df['UNEMP']\n",
    "\n",
    "# Define feature types\n",
    "categorical_features = ['Region']\n",
    "numerical_features = X.columns.difference(categorical_features)\n",
    "\n",
    "# Create and fit preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Save preprocessing parameters manually\n",
    "import json\n",
    "\n",
    "preprocessing_params = {\n",
    "    'numerical_features': list(numerical_features),\n",
    "    'categorical_features': categorical_features,\n",
    "    'scaler_mean': preprocessor.named_transformers_['num'].mean_.tolist(),\n",
    "    'scaler_scale': preprocessor.named_transformers_['num'].scale_.tolist(),\n",
    "    'encoder_categories': [cat.tolist() for cat in preprocessor.named_transformers_['cat'].categories_]\n",
    "}\n",
    "\n",
    "with open('preprocessing_params.json', 'w') as f:\n",
    "    json.dump(preprocessing_params, f, indent=2)\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(X_processed.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.02),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.02),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Create reproducible train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, y, test_size=0.1, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=300, \n",
    "          batch_size=8, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[early_stop],\n",
    "          verbose=1)\n",
    "\n",
    "# Evaluate model performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_processed)\n",
    "\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"RÂ² Score: {r2:.2f}\")\n",
    "\n",
    "# Save trained model\n",
    "model.save('Unemployment_AI_Revisions.keras')\n",
    "\n",
    "# Test prediction on example data\n",
    "new_data = pd.DataFrame({\n",
    "    'Region': ['Europe and Central Asia'],  \n",
    "    'Trade union density': [78.699997],\n",
    "    'Combined corporate income tax rate': [28.0],\n",
    "    'Education spending': [0.0734319847255705],\n",
    "    'Health spending': [0.0631525528524754],\n",
    "    'Housing spending': [0.0057497428086187],\n",
    "    'Community development spending': [0.0025634702523358],\n",
    "    'IRLT': [5.1075],\n",
    "    'Population, total': [8895960.0],\n",
    "    'GDP per capita (current US$)': [27259.4806735435],\n",
    "    'Inflation, consumer prices (annual %)': [2.40595834145438],\n",
    "    'Gini index': [26.5]\n",
    "})\n",
    "\n",
    "new_data_processed = preprocessor.transform(new_data)\n",
    "predicted_unemployment = model.predict(new_data_processed, verbose=0)\n",
    "print(f\"\\nPredicted Unemployment: {predicted_unemployment.flatten()[0]:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp-finaltest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
